{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pdfplumber\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model and vectorizer\n",
    "bc = pickle.load(open('/Users/macbookair/Desktop/project/Resume_Analyser/resume-job-matching/models/bc_model.pkl', 'rb'))\n",
    "tfidf = pickle.load(open('/Users/macbookair/Desktop/project/Resume_Analyser/resume-job-matching/models/tfidf_vectorizer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s+]', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'\\d{10,}', '', text) \n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_tokens(tokens):\n",
    "    doc = nlp(' '.join(tokens))\n",
    "    return [token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_SPECIFIC_STOPWORDS = ['resume', 'job', 'candidate', 'apply', 'experience', 'skills']\n",
    "stop_words = set(stopwords.words('english')).union(DOMAIN_SPECIFIC_STOPWORDS)\n",
    "\n",
    "def remove_stopwords_from_tokens(tokens):\n",
    "    return [word for word in tokens if word.lower() not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a single PDF file.\"\"\"\n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            full_text = ''\n",
    "            for page in pdf.pages:\n",
    "                full_text += page.extract_text() or ''  # Extract text from all pages\n",
    "            return full_text.strip()  # Clean up whitespace\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {pdf_path}: {e}\")\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = '/Users/macbookair/Desktop/project/Resume_Analyser/resume-job-matching/data/Resume/resume_en.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_text = extract_text_from_pdf(resume)\n",
    "cleaned_resume = cleanText(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Juan Jose Carin\\nMountain View, CA 94041\\n650-336-4590 | juanjose.carin@gmail.com\\nData Scientist\\nlinkedin.com/in/juanjosecarin | juanjocarin.github.io\\nProfessional Profile\\nPassionate about data analysis and experiments, mainly focused on user behavior, experience, and engagement, with a solid\\nbackground in data science and statistics, and extensive experience using data insights to drive business growth.\\nEducation\\n2016 University of California, Berkeley Master of Information and Data Science GPA: 3.93\\nRelevant courses: • Field Experiments • Data Visualization and\\n• Machine Learning • Applied Regression and Time Series Communication\\n• Machine Learning at Scale Analysis • Research Design and Applications for\\n• Storing and Retrieving Data • Exploring and Analyzing Data Data Analysis\\n2014 Universidad Politécnica de Madrid M.S. in Statistical and Computational Information Processing GPA: 3.69\\nRelevant courses: • Neural Networks and Statistical • Monte Carlo Techniques\\n• Data Mining Learning • Numerical Methods in Finance\\n• Multivariate Analysis • Regression and Prediction Methods • Stochastic Models in Finance\\n• Time Series • Optimization Techniques • Bayesian Networks\\n2005 Universidad Politécnica de Madrid M.S. in Telecommunication Engineering GPA: 3.03\\nFocus Area: Radio communication systems (radar and mobile).\\nFellowship: First year at University, due to Honors obtained last year at high school.\\nSkills\\nProgramming / Statistics Big Data Visualization Others\\nProficient: R, Python, SQL Hadoop, Hive, MrJob Tableau Git, AWS\\nIntermediate: SPSS, SAS, Matlab Spark, Storm Bash\\nBasic: EViews, Demetra+ D3.js Gephi, Neo4j, QGIS\\nExperience\\nDATA SCIENCE\\nJan. 2016 – Mar. 2016 Data Scientist\\nCONENTO Madrid, Spain (working remotely)\\n• Designed and implemented the ETL pipeline for a predictive model of traffic on the main roads in\\neastern Spain (a project for the Spanish government).\\n• Automated scripts in R to extract, transform, clean (incl. anomaly detection), and load into MySQL\\ndata from multiple data sources: road traffic sensors, accidents, road works, weather.\\nJun. 2014 – Sep. 2014 Data Scientist\\nCONENTO Madrid, Spain\\n• Designed an experiment for Google Spain (conducted in October 2014) to measure the impact of\\nYouTube ads on the sales of a car manufacturer's dealer network.\\n• A matched-pair, cluster-randomized design, which involved selecting the test and control groups\\nfrom a sample of 50+ cities in Spain (where geo-targeted ads were possible) based on their sales-\\nwise similarity over time, using wavelets (and R).\\nMANAGEMENT – SALES (Electrical Eng.)\\nFeb. 2009 – Aug. 2013 Head of Sales, Spain & Portugal – Test &Measurement dept.\\nYOKOGAWA Madrid, Spain\\n• Applied analysis of sales and market trends to decide the direction of the department.\\n• Led a team of 7 people.\\n1 of 2Juan Jose Carin\\nMountain View, CA 94041\\n650-336-4590 | juanjose.carin@gmail.com\\nData Scientist\\nlinkedin.com/in/juanjosecarin | juanjocarin.github.io\\n• Increased revenue by 6.3%, gross profit by 4.2%, and operating income by 146%, and achieved a 30%\\nratio of new customers (3x growth), by entering new markets and improving customer service and\\ntraining.\\nSALES (Electrical Eng. & Telecom.)\\nApr. 2008 – Jan. 2009 Sales Engineer – Test & Measurement dept.\\nYOKOGAWA Madrid, Spain\\n• Promoted to head of sales after 5 months leading the sales team.\\nSep. 2004 – Mar. 2008 Sales & Application Engineer\\nAYSCOM Madrid, Spain\\n• Exceeded sales target every year from 2005 to 2007 (achieved 60% of the target in the first 3 months\\nof 2008).\\nEDUCATION\\nJul. 2002 – Jun. 2004 Tutor of Differential & Integral Calculus, Physics, and Digital Electronic Circuits\\nACADEMIA UNIVERSITARIA Madrid, Spain\\n• Highest-rated professor in student surveys, in 4 of the 6 terms.\\n• Increased ratio of students passing the course by 25%.\\nProjects\\nSee juanjocarin.github.io for additional information\\n2016 SmartCam\\nCapstone Python, OpenCV, TensorFlow, AWS (EC2, S3, DynamoDB)\\nA scalable cloud-based video monitoring system that features motion detection, face counting, and image recognition.\\n2015 Implementation of the Shortest Path and PageRank algorithms with the Wikipedia graph dataset\\nMachine Learning at Scale Hadoop MrJob, Python, AWS EC2, AWS S3\\nUsing a graph dataset of almost half a million nodes.\\n2015 Forest cover type prediction\\nMachine Learning Python, Scikit-Learn, Matplotlib\\nA Kaggle competition: predictions of the predominant kind of tree cover, from strictly cartographic variables such as elevation\\nand soil type, using random forests, SVMs, kNNs, Naive Bayes, Gradient Descent, GMMs, …\\n2015 Redefining the job search process\\nStoring and Retrieving Data Hadoop HDFS, Hive, Spark, Python, AWS EC2, Tableau\\nA pipeline that combines data from Indeed API and the U.S. Census Bureau to select the best locations for data scientists\\nbased on the number of job postings, housing cost, etc.\\n2015 A fresh perspective on Citi Bike\\nData Visualization and Communication Tableau, SQLite\\nAn interactive website to visualize NYC Citi Bike bicycle sharing service.\\n2015 Investigating the effect of competition on the ability to solve arithmetic problems\\nField Experiments R\\nA randomized controlled trial in which 300+ participants were assigned to a control group or one of two test groups to\\nevaluate the effect of competition (being compared to no one or someone better or worse).\\n2014 Prediction of customer churn for a mobile network carrier\\nData Mining SAS\\nPredictions from a sample of 45,000+ customers, using tree decisions, logistic regression, and neural networks.\\n2014 Different models of Harmonized Index of Consumer Prices (HICP) in Spain\\nTime Series SPSS, Demetra+\\nForecasts based on exponential smoothing, ARIMA, and transfer function (using petrol price as independent variable) models.\\n2 of 2\""
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(cleaned_resume)\n",
    "tokens = remove_stopwords_from_tokens(tokens)\n",
    "lemmatized_tokens = lemmatize_tokens(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_resume_text = ' '.join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_vectorized = tfidf.transform([final_resume_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = bc.predict(resume_vectorized)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {0: 'accountant', 1: 'advocate', 2: 'agriculture', 3: 'apparel', 4: 'arts', 5: 'automation testing', 6: 'automobile', 7: 'aviation', 8: 'banking', 9: 'blockchain', 10: 'bpo', 11: 'business analyst', 12: 'business-development', 13: 'chef', 14: 'civil engineer', 15: 'construction', 16: 'consultant', 17: 'data science', 18: 'database', 19: 'designer', 20: 'devops engineer', 21: 'digital-media', 22: 'dotnet developer', 23: 'electrical engineering', 24: 'engineering', 25: 'etl developer', 26: 'finance', 27: 'fitness', 28: 'hadoop', 29: 'health and fitness', 30: 'healthcare', 31: 'hr', 32: 'information-technology', 33: 'java developer', 34: 'mechanical engineer', 35: 'network security engineer', 36: 'operations manager', 37: 'pmo', 38: 'public-relations', 39: 'python developer', 40: 'sales', 41: 'sap developer', 42: 'teacher', 43: 'testing', 44: 'web designing'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: sales\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "category_name = category_mapping.get(prediction, \"Unknown\")\n",
    "\n",
    "print(\"Predicted Category:\", category_name)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgr = pickle.load(open('/Users/macbookair/Desktop/project/Resume_Analyser/resume-job-matching/models/lgr_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_lgr = lgr.predict(resume_vectorized)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: sales\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "category_name = category_mapping.get(prediction_lgr, \"Unknown\")\n",
    "\n",
    "print(\"Predicted Category:\", category_name)\n",
    "print(prediction_lgr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
